import cv2
import os
import numpy as np
import shutil
from tqdm import tqdm
import random
import mediapipe as mp
from scipy.spatial import distance

# Kh·ªüi t·∫°o MediaPipe Face Detection
mp_face_detection = mp.solutions.face_detection
face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)

def ensure_dir(directory):
    """ƒê·∫£m b·∫£o th∆∞ m·ª•c t·ªìn t·∫°i, n·∫øu kh√¥ng t·∫°o m·ªõi"""
    if not os.path.exists(directory):
        os.makedirs(directory)

def detect_and_crop_face(image, target_size=224, padding_percent=0.2):
    """
    Ph√°t hi·ªán, c·∫Øt khu√¥n m·∫∑t th√†nh h√¨nh vu√¥ng v√† resize v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh
    
    Args:
        image: ·∫¢nh ƒë·∫ßu v√†o
        target_size: K√≠ch th∆∞·ªõc ƒë√≠ch c·ªßa ·∫£nh ƒë·∫ßu ra (pixel)
        padding_percent: Ph·∫ßn trƒÉm padding th√™m v√†o xung quanh khu√¥n m·∫∑t (0.2 = 20%)
        
    Returns:
        ·∫¢nh khu√¥n m·∫∑t ƒë√£ c·∫Øt th√†nh h√¨nh vu√¥ng v√† resize ho·∫∑c None n·∫øu kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t
    """
    # Chuy·ªÉn ƒë·ªïi sang RGB
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # Ph√°t hi·ªán khu√¥n m·∫∑t
    results = face_detection.process(image_rgb)
    
    # Ki·ªÉm tra n·∫øu kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c khu√¥n m·∫∑t
    if not results.detections:
        return None
    
    # L·∫•y khu√¥n m·∫∑t ƒë·∫ßu ti√™n c√≥ ƒë·ªô tin c·∫≠y cao nh·∫•t
    detection = results.detections[0]
    bboxC = detection.location_data.relative_bounding_box
    
    # L·∫•y k√≠ch th∆∞·ªõc ·∫£nh
    ih, iw, _ = image.shape
    
    # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô t∆∞∆°ng ƒë·ªëi sang t·ªça ƒë·ªô tuy·ªát ƒë·ªëi
    x = int(bboxC.xmin * iw)
    y = int(bboxC.ymin * ih)
    w = int(bboxC.width * iw)
    h = int(bboxC.height * ih)
    
    # Ki·ªÉm tra n·∫øu khu√¥n m·∫∑t qu√° nh·ªè
    min_face_size = 50
    if w < min_face_size or h < min_face_size:
        return None
    
    # T√≠nh to√°n padding d·ª±a tr√™n ph·∫ßn trƒÉm k√≠ch th∆∞·ªõc khu√¥n m·∫∑t
    padding_x = int(w * padding_percent)
    padding_y = int(h * padding_percent)
    
    # T√≠nh to√°n t√¢m c·ªßa khu√¥n m·∫∑t
    center_x = x + w // 2
    center_y = y + h // 2
    
    # X√°c ƒë·ªãnh k√≠ch th∆∞·ªõc l·ªõn nh·∫•t gi·ªØa chi·ªÅu r·ªông v√† chi·ªÅu cao (v·ªõi padding)
    size = max(w + 2 * padding_x, h + 2 * padding_y)
    
    # T√≠nh to√°n t·ªça ƒë·ªô m·ªõi ƒë·ªÉ c·∫Øt h√¨nh vu√¥ng t·ª´ t√¢m
    new_x = max(0, center_x - size // 2)
    new_y = max(0, center_y - size // 2)
    
    # ƒê·∫£m b·∫£o khu√¥n m·∫∑t n·∫±m trong ·∫£nh
    if new_x + size > iw:
        new_x = iw - size
    if new_y + size > ih:
        new_y = ih - size
    
    # ƒê·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° k√≠ch th∆∞·ªõc ·∫£nh
    if new_x < 0:
        new_x = 0
    if new_y < 0:
        new_y = 0
    
    size = min(size, iw - new_x, ih - new_y)
    
    # C·∫Øt khu√¥n m·∫∑t th√†nh h√¨nh vu√¥ng
    face_image = image[new_y:new_y+size, new_x:new_x+size]
    
    # Resize v·ªÅ k√≠ch th∆∞·ªõc c·ªë ƒë·ªãnh
    face_image = cv2.resize(face_image, (target_size, target_size), interpolation=cv2.INTER_AREA)
    
    return face_image



def extract_diverse_frames_from_video(video_path, output_folder, target_frames=300, target_size=224):
    """Tr√≠ch xu·∫•t 150 ·∫£nh khu√¥n m·∫∑t ch·∫•t l∆∞·ª£ng cao nh·∫•t t·ª´ video"""
    ensure_dir(output_folder)
    
    # Kh·ªüi t·∫°o MediaPipe Face Mesh ƒë·ªÉ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng
    import mediapipe as mp
    mp_face_mesh = mp.solutions.face_mesh
    face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5)
    
    video = cv2.VideoCapture(video_path)
    if not video.isOpened():
        print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video {video_path}")
        return 0
    
    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"üéØ M·ª•c ti√™u: {target_frames} ·∫£nh ch·∫•t l∆∞·ª£ng cao t·ª´ {total_frames} frames")
    
    # L·∫•y m·∫´u frame c√°ch ƒë·ªÅu t·ª´ video (l·∫•y nhi·ªÅu ƒë·ªÉ ch·ªçn l·ªçc)
    sample_indices = np.linspace(0, total_frames-1, min(total_frames, target_frames*3), dtype=int)
    
    face_candidates = []
    
    print("üîç Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t...")
    for frame_idx in tqdm(sample_indices):
        video.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = video.read()
        if not ret:
            continue
            
        # Ph√°t hi·ªán khu√¥n m·∫∑t
        face_image = detect_and_crop_face(frame, target_size)
        if face_image is None:
            continue
            
        # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng b·∫±ng MediaPipe
        quality_score = evaluate_face_quality_mediapipe(face_image, face_mesh)
        
        face_candidates.append((frame_idx, face_image, quality_score))
    
    video.release()
    face_mesh.close()
    
    if not face_candidates:
        print("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t n√†o!")
        return 0
    
    # S·∫Øp x·∫øp theo ch·∫•t l∆∞·ª£ng v√† l·∫•y top 150
    face_candidates.sort(key=lambda x: x[2], reverse=True)
    selected_faces = face_candidates[:target_frames]
    
    print(f"üíæ L∆∞u {len(selected_faces)} ·∫£nh ch·∫•t l∆∞·ª£ng cao nh·∫•t...")
    for i, (frame_idx, face_image, quality) in enumerate(selected_faces):
        filename = os.path.join(output_folder, f"face_{i:03d}_q{quality:.2f}.jpg")
        cv2.imwrite(filename, face_image)
    
    print(f"‚úÖ ƒê√£ l∆∞u {len(selected_faces)} ·∫£nh khu√¥n m·∫∑t ch·∫•t l∆∞·ª£ng cao")
    return len(selected_faces)

def evaluate_face_quality_mediapipe(face_image, face_mesh):
    """ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng khu√¥n m·∫∑t b·∫±ng MediaPipe"""
    # Chuy·ªÉn RGB cho MediaPipe
    rgb_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_image)
    
    # ƒêi·ªÉm c∆° b·∫£n t·ª´ ƒë·ªô s·∫Øc n√©t v√† s√°ng
    gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
    brightness = np.mean(gray)
    contrast = gray.std()
    
    # ƒêi·ªÉm th∆∞·ªüng n·∫øu ph√°t hi·ªán ƒë∆∞·ª£c face landmarks
    landmark_bonus = 0
    if results.multi_face_landmarks:
        landmark_bonus = 0.5  # C√≥ landmarks = t·ªët h∆°n
    
    # ƒêi·ªÉm s√°ng t·ªëi ∆∞u (128 = l√Ω t∆∞·ªüng)
    brightness_score = 1 - abs(brightness - 128) / 128
    
    # T·ªïng ƒëi·ªÉm
    quality = sharpness/1000 + contrast/100 + brightness_score + landmark_bonus
    return quality

def extract_faces_from_all_videos(video_folder, raw_folder, target_frames=300, target_size=224):
    """X·ª≠ l√Ω t·∫•t c·∫£ video, tr√≠ch xu·∫•t 150 ·∫£nh ch·∫•t l∆∞·ª£ng cao nh·∫•t"""
    ensure_dir(raw_folder)
    videos = [f for f in os.listdir(video_folder) if f.endswith(('.mp4', '.avi', '.mov'))]
    
    print(f"üéØ T√¨m th·∫•y {len(videos)} video, m·ªói video s·∫Ω t·∫°o {target_frames} ·∫£nh ch·∫•t l∆∞·ª£ng cao")
    
    for video in videos:
        video_path = os.path.join(video_folder, video)
        student_id = os.path.splitext(video)[0]
        raw_student_folder = os.path.join(raw_folder, student_id)
        ensure_dir(raw_student_folder)
        
        print(f"\nüìπ X·ª≠ l√Ω: {video}")
        num_extracted = extract_diverse_frames_from_video(video_path, raw_student_folder, target_frames, target_size)
        print(f"‚úÖ {student_id}: {num_extracted} ·∫£nh")
    
    print(f"\nüéâ Ho√†n th√†nh! T·∫°o ~{target_frames} ·∫£nh ch·∫•t l∆∞·ª£ng cao cho {len(videos)} sinh vi√™n")

if __name__ == "__main__":
    project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    video_folder = os.path.join(project_dir, "data", "videos")
    raw_folder = os.path.join(project_dir, "data", "raw")
    
    print("üéØ TR√çCH XU·∫§T 150 ·∫¢NH CH·∫§T L∆Ø·ª¢NG CAO/VIDEO")
    print("=" * 50)
    
    if not os.path.exists(video_folder):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {video_folder}")
    else:
        extract_faces_from_all_videos(video_folder, raw_folder, target_frames=300)